{
  "test_cases": [
    {
      "question": "什么是 RAG（Retrieval Augmented Generation）？",
      "ground_truth": "RAG 是一种结合信息检索和文本生成的技术。它首先从知识库中检索相关文档，然后将这些文档作为上下文输入到大语言模型中，生成更准确、更有依据的回答。RAG 的主要优势是能够访问外部知识，减少幻觉，提供可追溯的答案来源。",
      "context_keywords": ["检索", "生成", "知识库", "上下文", "大语言模型"]
    },
    {
      "question": "RAG 系统的主要组成部分有哪些？",
      "ground_truth": "RAG 系统主要包含三个核心组成部分：1) 文档处理模块，负责文档加载、分块和向量化；2) 检索模块，使用向量数据库进行相似度搜索，找到与查询最相关的文档片段；3) 生成模块，将检索到的上下文和用户查询输入到 LLM 中生成回答。此外还包括嵌入模型、向量数据库等基础组件。",
      "context_keywords": ["文档处理", "检索", "生成", "向量数据库", "嵌入模型"]
    },
    {
      "question": "向量数据库在 RAG 中扮演什么角色？",
      "ground_truth": "向量数据库在 RAG 中负责存储文档的向量表示（embeddings），并提供高效的相似度搜索功能。当用户提出查询时，系统会将查询转换为向量，然后在向量数据库中搜索最相似的文档向量，快速找到相关内容。常见的向量数据库包括 ChromaDB、Pinecone、Weaviate、Milvus 等。",
      "context_keywords": ["向量存储", "embeddings", "相似度搜索", "ChromaDB"]
    },
    {
      "question": "什么是 Embedding（嵌入）？",
      "ground_truth": "Embedding 是将文本转换为固定维度的数值向量的过程。这些向量能够捕捉文本的语义信息，使得语义相似的文本在向量空间中距离较近。在 RAG 系统中，文档和查询都会被转换为 embeddings，通过计算向量相似度来找到最相关的文档。常用的嵌入模型包括 OpenAI embeddings、sentence-transformers 等。",
      "context_keywords": ["向量", "语义", "相似度", "文本表示"]
    },
    {
      "question": "RAG 中的文档分块（Chunking）为什么重要？",
      "ground_truth": "文档分块是将长文档切分成较小片段的过程，这在 RAG 中非常重要，原因有：1) LLM 有上下文长度限制；2) 较小的块能提供更精确的检索结果；3) 有助于减少噪音，提高答案质量。分块时需要考虑块大小（chunk size）和重叠（overlap），以保证语义完整性。常见的分块大小在 200-1000 tokens 之间。",
      "context_keywords": ["文档切分", "chunk size", "overlap", "上下文长度"]
    },
    {
      "question": "什么是混合检索（Hybrid Retrieval）？",
      "ground_truth": "混合检索结合了多种检索方法，通常是向量检索（semantic search）和关键词检索（如 BM25）。向量检索擅长捕捉语义相似度，而 BM25 擅长精确的关键词匹配。通过融合算法（如 RRF - Reciprocal Rank Fusion）整合两种方法的结果，可以获得更好的检索性能，既能理解语义又不会错过重要的关键词匹配。",
      "context_keywords": ["向量检索", "BM25", "语义搜索", "关键词匹配", "RRF"]
    },
    {
      "question": "Cross-Encoder 重排（Reranking）的作用是什么？",
      "ground_truth": "Cross-Encoder 重排是在初步检索后对结果进行精细排序的过程。与 bi-encoder（用于初始检索）不同，cross-encoder 会同时处理查询和文档，计算更精确的相关性分数。虽然速度较慢，但准确度更高。在 RAG 流程中，通常先用快速的向量检索获得候选集，再用 cross-encoder 对候选进行重排，选出最相关的文档用于生成。",
      "context_keywords": ["重排", "相关性评分", "bi-encoder", "精确匹配"]
    },
    {
      "question": "RAG 系统如何减少大模型的幻觉（Hallucination）？",
      "ground_truth": "RAG 通过以下方式减少幻觉：1) 提供真实的文档上下文，让模型基于事实回答而非臆造；2) 明确要求模型只根据提供的上下文回答；3) 提供答案来源，便于验证；4) 当上下文中没有相关信息时，引导模型承认不知道。此外，使用合适的 prompt engineering 和设置较低的 temperature 参数也有助于减少幻觉。",
      "context_keywords": ["事实依据", "上下文", "答案来源", "prompt engineering"]
    },
    {
      "question": "什么是查询扩展（Query Expansion）？",
      "ground_truth": "查询扩展是将用户的原始查询改写或扩展为多个相关查询的技术。这可以通过：1) 使用 LLM 生成查询的不同表述；2) 添加同义词；3) 从不同角度重新表达问题。查询扩展能提高检索召回率，因为同一个信息可能在文档中以不同方式表达。在 RAG 中，通常会对所有扩展查询分别检索，然后融合结果。",
      "context_keywords": ["查询改写", "多查询", "召回率", "同义词"]
    },
    {
      "question": "MMR（Maximal Marginal Relevance）算法的目的是什么？",
      "ground_truth": "MMR 算法旨在平衡检索结果的相关性和多样性。它不仅考虑文档与查询的相似度，还会降低与已选文档高度相似的文档的排名，从而避免返回内容重复的文档。MMR 通过 lambda 参数控制相关性和多样性的权重：lambda=1 完全关注相关性，lambda=0 完全关注多样性。在 RAG 中使用 MMR 可以确保提供给 LLM 的上下文信息更加多样和全面。",
      "context_keywords": ["多样性", "相关性", "去重", "lambda 参数"]
    },
    {
      "question": "向量检索中的相似度计算方法有哪些？",
      "ground_truth": "常见的向量相似度计算方法包括：1) 余弦相似度（Cosine Similarity）- 计算向量夹角，范围 [-1, 1]；2) 点积（Dot Product）- 向量内积，考虑向量长度；3) 欧氏距离（Euclidean Distance）- 向量间的直线距离；4) 曼哈顿距离（Manhattan Distance）。在 RAG 中，余弦相似度最常用，因为它关注方向而非长度，适合归一化的 embeddings。",
      "context_keywords": ["余弦相似度", "点积", "欧氏距离", "向量计算"]
    },
    {
      "question": "什么是 Few-shot Learning 在 RAG 中的应用？",
      "ground_truth": "Few-shot Learning 是在 prompt 中提供少量示例来引导模型行为的技术。在 RAG 中，可以在 prompt 中包含几个「问题-上下文-答案」的示例，帮助模型理解如何使用检索到的上下文来生成回答。这种方法特别适合需要特定格式或风格的回答场景，如技术文档问答、客服对话等。相比 zero-shot，few-shot 通常能获得更稳定和符合预期的输出。",
      "context_keywords": ["prompt", "示例", "引导", "输出格式"]
    },
    {
      "question": "RAG 系统的评估指标有哪些？",
      "ground_truth": "RAG 系统的评估可分为检索和生成两部分：检索评估包括准确率（Precision）、召回率（Recall）、NDCG、MRR 等；生成评估包括 BLEU、ROUGE、BERTScore 等。此外还有端到端评估指标如 Faithfulness（忠实度，答案是否基于上下文）、Answer Relevancy（答案相关性）、Context Precision 和 Context Recall。Ragas 框架提供了这些专门的 RAG 评估指标。",
      "context_keywords": ["准确率", "召回率", "faithfulness", "relevancy", "ragas"]
    },
    {
      "question": "如何优化 RAG 系统的检索性能？",
      "ground_truth": "优化 RAG 检索性能的方法包括：1) 选择合适的嵌入模型（如针对中文的 bge 系列）；2) 调整 chunk size 和 overlap；3) 使用混合检索结合语义和关键词；4) 应用重排序（reranking）；5) 使用查询扩展；6) 实现缓存机制；7) 优化向量数据库索引（如 HNSW、IVF）；8) 根据业务场景微调嵌入模型。此外，A/B 测试和持续的评估也很重要。",
      "context_keywords": ["嵌入模型", "混合检索", "重排序", "缓存", "索引优化"]
    },
    {
      "question": "Prompt Engineering 在 RAG 中的重要性是什么？",
      "ground_truth": "Prompt Engineering 在 RAG 中至关重要，好的 prompt 可以：1) 明确指示模型使用检索到的上下文；2) 防止模型产生幻觉；3) 控制输出格式和风格；4) 处理上下文不足的情况；5) 引导模型引用来源。典型的 RAG prompt 包含系统角色说明、上下文文档、用户问题和回答要求。此外还要考虑上下文长度限制和 token 成本。",
      "context_keywords": ["prompt 设计", "系统角色", "输出控制", "上下文使用"]
    },
    {
      "question": "什么是语义缓存（Semantic Cache）？",
      "ground_truth": "语义缓存是缓存相似查询结果的技术。与传统的精确匹配缓存不同，语义缓存使用向量相似度判断查询是否相似。当新查询与缓存中的查询相似度超过阈值时，直接返回缓存结果。这可以显著降低成本和延迟，特别是对于重复或相似的常见问题。实现时需要权衡相似度阈值：过高则缓存命中率低，过低则可能返回不准确的缓存结果。",
      "context_keywords": ["缓存", "相似查询", "向量相似度", "性能优化"]
    },
    {
      "question": "RAG 中如何处理多语言文档？",
      "ground_truth": "处理多语言文档的策略包括：1) 使用多语言嵌入模型（如 multilingual-e5、LaBSE）；2) 实现语言检测并路由到对应的语言处理流程；3) 使用多语言 LLM（如 GPT-4、Claude）；4) 对于翻译场景，可以先翻译查询或文档；5) 建立语言特定的索引和检索管道。关键是确保查询和文档在同一个向量空间中，或使用支持跨语言检索的模型。",
      "context_keywords": ["多语言", "嵌入模型", "跨语言检索", "语言检测"]
    },
    {
      "question": "什么是 Agent-based RAG？",
      "ground_truth": "Agent-based RAG 是让 AI Agent 自主决定何时、如何使用 RAG 的方法。Agent 可以：1) 判断问题是否需要检索外部知识；2) 决定检索的深度和广度；3) 根据初步结果决定是否需要二次检索；4) 整合多个知识源；5) 迭代优化检索策略。这种方法通过 ReAct、Tool Use 等技术实现，使 RAG 系统更加智能和灵活，适合复杂的多步骤推理任务。",
      "context_keywords": ["AI Agent", "自主决策", "工具使用", "ReAct", "迭代检索"]
    },
    {
      "question": "RAG 系统如何处理实时更新的数据？",
      "ground_truth": "处理实时数据更新的方法包括：1) 增量索引 - 只对新增或修改的文档生成向量；2) 版本控制 - 标记文档版本和时间戳；3) 定期重建索引 - 根据更新频率安排全量重建；4) 使用支持实时更新的向量数据库；5) 实现文档级别的删除和更新 API；6) 缓存失效策略 - 文档更新时清除相关缓存。对于高频更新场景，可以考虑使用流式处理框架或数据库的 CDC 机制。",
      "context_keywords": ["增量索引", "实时更新", "版本控制", "缓存失效"]
    },
    {
      "question": "如何评估检索到的上下文质量？",
      "ground_truth": "评估上下文质量的方法包括：1) Context Precision - 检索结果中相关文档的比例；2) Context Recall - 相关文档被检索到的比例；3) 人工标注 - 对采样结果进行人工评估；4) 使用 LLM 作为评判者 - 让模型评估上下文是否包含回答问题所需的信息；5) A/B 测试 - 对比不同检索策略的效果；6) 用户反馈 - 收集用户对答案质量的评价。Ragas 等框架提供了自动化的上下文质量评估工具。",
      "context_keywords": ["context precision", "context recall", "质量评估", "人工标注"]
    },
    {
      "question": "什么是 RRF（Reciprocal Rank Fusion）算法？",
      "ground_truth": "RRF 是一种融合多个检索结果排序的算法。它通过计算每个文档在不同检索方法中的倒数排名来综合评分。RRF 的优势是简单有效，不需要对不同检索方法的分数进行归一化。公式为：RRF(d) = Σ 1/(k + rank(d))，其中 k 是平滑参数（通常为60）。在混合检索中，RRF 常用于融合向量检索和 BM25 的结果，比简单的加权平均更鲁棒。",
      "context_keywords": ["融合算法", "排名", "混合检索", "倒数排名"]
    },
    {
      "question": "向量数据库的索引类型有哪些？",
      "ground_truth": "常见的向量索引类型包括：1) Flat（暴力搜索）- 精确但慢，适合小数据集；2) IVF（倒排文件）- 将向量聚类，搜索时只查相关簇；3) HNSW（分层导航小世界图）- 构建图结构，速度快且准确；4) PQ（乘积量化）- 压缩向量，节省内存；5) ANNOY - 构建树结构，适合静态数据。选择索引需要平衡准确度、速度和内存。HNSW 是目前最流行的选择，提供良好的速度-准确度权衡。",
      "context_keywords": ["索引", "HNSW", "IVF", "向量搜索", "ANN"]
    },
    {
      "question": "什么是文档元数据（Metadata）在 RAG 中的作用？",
      "ground_truth": "元数据是描述文档的附加信息，如作者、日期、来源、文档类型等。在 RAG 中，元数据可以：1) 用于过滤 - 限制检索范围（如只搜索特定时期的文档）；2) 增强检索 - 结合内容和元数据进行混合搜索；3) 提供上下文 - 告知 LLM 信息来源和可信度；4) 用户展示 - 显示答案来源的详细信息；5) 权重调整 - 根据文档权威性调整检索分数。合理使用元数据能显著提升 RAG 系统的实用性。",
      "context_keywords": ["元数据", "过滤", "来源信息", "文档属性"]
    },
    {
      "question": "BM25 算法的工作原理是什么？",
      "ground_truth": "BM25（Best Matching 25）是一种基于词频的排序算法。它考虑：1) 词频（TF）- 词在文档中出现的频率，但使用饱和函数避免过度奖励高频词；2) 逆文档频率（IDF）- 罕见词获得更高权重；3) 文档长度归一化 - 避免长文档占优。BM25 有两个参数：k1 控制词频饱和度，b 控制长度归一化强度。虽然不理解语义，但 BM25 在关键词精确匹配上表现优异，是混合检索中的重要组成部分。",
      "context_keywords": ["关键词检索", "词频", "TF-IDF", "排序算法"]
    },
    {
      "question": "如何选择合适的 Chunk Size？",
      "ground_truth": "选择 chunk size 需要平衡多个因素：1) 过小的块（<200 tokens）- 可能切断语义，但检索精确；2) 过大的块（>1000 tokens）- 保留完整语义，但可能包含无关信息；3) LLM 上下文窗口 - 确保总上下文不超限；4) 文档类型 - 技术文档可能需要较大块以保持代码完整性，而问答对适合小块。建议从 512 tokens 开始，通过实验找到最佳值。同时考虑 overlap（通常是 chunk size 的 10-20%）以避免边界信息丢失。",
      "context_keywords": ["分块大小", "语义完整性", "检索精度", "上下文窗口"]
    },
    {
      "question": "什么是 Self-Query 在 RAG 中的应用？",
      "ground_truth": "Self-Query 是让 LLM 自动将自然语言查询转换为结构化查询的技术。例如，用户问「2023年的销售报告」，系统会提取：1) 查询内容：「销售报告」；2) 元数据过滤：year=2023。这使得 RAG 系统能理解查询中的过滤条件，而不仅仅是语义搜索。Self-Query 通常通过 function calling 或特定的 prompt 实现，能显著提升检索准确度，特别是在有丰富元数据的场景中。",
      "context_keywords": ["查询理解", "元数据过滤", "结构化查询", "LLM能力"]
    },
    {
      "question": "RAG 系统中的流式输出（Streaming）有什么好处？",
      "ground_truth": "流式输出是指 LLM 逐个 token 生成并返回结果，而非等待完整生成。好处包括：1) 用户体验 - 立即看到输出，感知延迟更短；2) 处理长回答 - 避免等待时间过长；3) 实时反馈 - 用户可以提前判断答案方向，必要时中断；4) 错误处理 - 如果生成出错，已输出的部分仍可见。实现时需要使用 SSE（Server-Sent Events）或 WebSocket。流式输出是现代 RAG 应用的标配功能。",
      "context_keywords": ["流式输出", "SSE", "用户体验", "实时生成"]
    },
    {
      "question": "什么是 HyDE（Hypothetical Document Embeddings）？",
      "ground_truth": "HyDE 是一种先用 LLM 生成假设性答案，再用该答案检索的技术。流程是：1) 用户提问；2) LLM 生成一个假设的答案文档（即使可能不准确）；3) 用假设答案的 embedding 检索；4) 用检索到的真实文档重新生成答案。HyDE 的理念是「答案比问题更接近答案」- 假设答案在向量空间中更接近真实答案文档。这在问题和答案表述差异大的场景中特别有效，能提升检索召回率。",
      "context_keywords": ["假设性文档", "查询改写", "检索优化", "embedding策略"]
    },
    {
      "question": "RAG 中如何处理表格数据？",
      "ground_truth": "处理表格的策略包括：1) 转换为文本 - 将表格转为自然语言描述或 Markdown；2) 保留结构 - 存储表格的结构化表示，检索时提供给 LLM；3) 拆分单元格 - 将每行或重要单元格作为独立 chunk；4) 使用多模态模型 - 直接处理表格图像；5) 构建表格索引 - 为表格建立专门的元数据和检索逻辑。对于复杂表格，可以结合 caption 和周围文本增强理解。选择方法取决于表格复杂度和查询类型。",
      "context_keywords": ["表格处理", "结构化数据", "文本转换", "多模态"]
    },
    {
      "question": "什么是 RAG 中的 Parent Document Retrieval？",
      "ground_truth": "Parent Document Retrieval 是一种两层检索策略：1) 用小 chunks 进行精确检索；2) 返回时提供包含该 chunk 的更大文档（parent document）。这结合了小块的检索精度和大块的语义完整性。例如，检索时用 256 token 的块找到最相关段落，但给 LLM 的是整个 1000 token 的章节。这避免了上下文被截断的问题，同时保持检索准确度。实现时需要维护 chunk 到 parent 的映射关系。",
      "context_keywords": ["分层检索", "上下文扩展", "精确匹配", "语义完整性"]
    },
    {
      "question": "如何在 RAG 中实现引用追踪？",
      "ground_truth": "引用追踪让用户验证答案来源，实现方法包括：1) 存储 chunk 元数据 - 记录来源文档、页码、段落位置；2) 标记引用 - 让 LLM 在答案中标注信息来源（如[1][2]）；3) 返回源文档 - 提供原始文档片段给用户；4) 高亮显示 - 在 UI 中突出引用的具体句子；5) 相关性分数 - 显示每个引用的可信度。良好的引用系统能显著提升用户信任度，是企业级 RAG 应用的必备功能。",
      "context_keywords": ["引用", "来源追踪", "可信度", "文档溯源"]
    },
    {
      "question": "RAG 系统如何处理图片和多模态内容？",
      "ground_truth": "处理多模态内容的方法包括：1) 图片描述 - 使用视觉模型（如 CLIP、GPT-4V）为图片生成文本描述并索引；2) OCR - 提取图片中的文字；3) 多模态 embeddings - 使用支持图文的模型（如 CLIP）生成统一向量；4) 分离索引 - 为不同模态建立独立索引；5) 多模态 LLM - 使用 GPT-4V、Claude 3 等直接处理图片。对于图表和信息图，可以结合结构化提取和描述生成。",
      "context_keywords": ["多模态", "图像处理", "CLIP", "OCR", "视觉模型"]
    },
    {
      "question": "什么是 RAG 中的 Contextual Compression？",
      "ground_truth": "Contextual Compression 是在检索后压缩无关内容的技术。流程是：1) 初步检索获得候选文档；2) 使用 LLM 或专门模型提取与查询真正相关的句子或段落；3) 只将压缩后的相关内容传给最终生成的 LLM。这能：1) 减少 token 消耗；2) 降低噪音；3) 提高答案质量；4) 支持更多上下文在有限窗口内。实现可以用提示词让 LLM 提取相关内容，或使用专门的压缩模型如 LongLLMLingua。",
      "context_keywords": ["上下文压缩", "信息提取", "token优化", "噪音过滤"]
    },
    {
      "question": "如何评估 RAG 系统的端到端性能？",
      "ground_truth": "端到端评估需要综合考虑：1) 检索质量 - Precision、Recall、MRR、NDCG；2) 生成质量 - Faithfulness、Relevancy、BLEU、ROUGE；3) 系统性能 - 延迟、吞吐量、成本；4) 用户满意度 - 通过问卷或反馈收集；5) 业务指标 - 任务完成率、准确率。使用 Ragas、TruLens 等框架可以自动化评估。建议建立持续评估流程，包括单元测试、回归测试和 A/B 测试，确保系统改进不会降低其他方面表现。",
      "context_keywords": ["端到端评估", "性能指标", "用户满意度", "持续评估"]
    },
    {
      "question": "RAG 中的 Token 成本如何优化？",
      "ground_truth": "优化 token 成本的策略包括：1) 智能缓存 - 缓存常见查询结果；2) 上下文压缩 - 只传递相关内容；3) 模型选择 - 根据任务难度选择合适的模型（简单查询用小模型）；4) Prompt 优化 - 精简指令，避免冗余；5) 批处理 - 合并相似查询；6) 检索优化 - 提高检索准确度，减少不必要的 LLM 调用。监控每个环节的 token 使用，找出优化重点。对于高频应用，token 成本可能是主要支出。",
      "context_keywords": ["成本优化", "token管理", "缓存策略", "模型选择"]
    },
    {
      "question": "什么是 GraphRAG？",
      "ground_truth": "GraphRAG 是基于知识图谱的 RAG 方法。与传统向量检索不同，GraphRAG：1) 构建实体和关系的图结构；2) 通过图遍历找到相关信息；3) 能处理多跳推理（如「A的朋友的公司」）；4) 保留实体间的关系信息。优势是能回答需要关系推理的复杂问题，适合知识密集型应用。实现可以结合向量检索（找到实体）和图查询（扩展关系），或使用图神经网络。Microsoft 的 GraphRAG 是代表性实现。",
      "context_keywords": ["知识图谱", "关系推理", "图遍历", "多跳查询"]
    },
    {
      "question": "RAG 系统如何处理时间敏感的信息？",
      "ground_truth": "处理时间敏感信息的策略包括：1) 时间戳索引 - 为每个文档标记时间，检索时优先考虑新信息；2) 时间过滤 - 根据查询中的时间指示（如「最新」、「2024年」）过滤；3) 时间加权 - 给新文档更高的检索权重；4) 版本管理 - 保留文档的多个版本，必要时展示演变；5) 实时数据源 - 集成 API 获取最新数据。对于新闻、金融等领域，准确的时间处理至关重要。",
      "context_keywords": ["时间戳", "实时性", "版本控制", "时间过滤"]
    },
    {
      "question": "什么是 RAG 中的 Negative Sampling？",
      "ground_truth": "Negative Sampling 是在训练或评估时故意提供不相关文档的技术。目的是：1) 测试系统是否会被无关信息误导；2) 训练模型识别相关和不相关内容；3) 评估 Faithfulness - 模型是否会从不相关文档中提取信息。在评估时，可以混入明显不相关的文档，检查生成的答案是否受影响。这有助于识别系统的鲁棒性问题，确保模型不会「瞎编」来源。",
      "context_keywords": ["负样本", "鲁棒性", "干扰测试", "质量评估"]
    },
    {
      "question": "如何处理 RAG 中的长对话历史？",
      "ground_truth": "处理长对话历史的方法包括：1) 上下文窗口管理 - 保留最近 N 轮对话；2) 对话摘要 - 用 LLM 总结历史，保留关键信息；3) 相关性过滤 - 只保留与当前查询相关的历史；4) 分层存储 - 近期对话全量保留，历史对话只保留摘要；5) 记忆系统 - 提取和存储重要事实。对于 RAG，需要将对话历史和检索上下文一起管理，确保不超过 LLM 的上下文限制。",
      "context_keywords": ["对话管理", "上下文窗口", "摘要", "记忆系统"]
    },
    {
      "question": "RAG 系统的安全性考虑有哪些？",
      "ground_truth": "安全性考虑包括：1) 提示注入防护 - 防止用户通过查询操纵系统行为；2) 数据访问控制 - 确保用户只能检索有权限的文档；3) 敏感信息过滤 - 避免返回个人信息、密钥等；4) 输入验证 - 防止恶意输入；5) 输出审核 - 检查生成内容的安全性；6) 审计日志 - 记录所有查询和访问。企业级 RAG 需要集成身份认证、权限管理和合规检查。",
      "context_keywords": ["安全", "权限控制", "提示注入", "数据保护"]
    },
    {
      "question": "什么是 RAG 中的 Query Decomposition？",
      "ground_truth": "Query Decomposition 是将复杂查询分解为多个子查询的技术。例如，「比较 A 和 B 的优缺点」可分解为：1) A 的优点；2) A 的缺点；3) B 的优点；4) B 的缺点。每个子查询独立检索，最后综合回答。这能：1) 处理需要多方面信息的复杂问题；2) 提高检索覆盖度；3) 使答案更结构化。实现可以用 LLM 自动分解查询，或使用思维链（Chain of Thought）逐步推理。",
      "context_keywords": ["查询分解", "子查询", "复杂问题", "多步推理"]
    },
    {
      "question": "如何在 RAG 中实现个性化？",
      "ground_truth": "个性化策略包括：1) 用户画像 - 根据用户历史、偏好调整检索和生成；2) 上下文个性化 - 考虑用户的角色、知识水平；3) 检索偏好 - 某些用户偏好详细回答，某些偏好简洁；4) 领域适配 - 根据用户所在领域调整术语和示例；5) 反馈学习 - 从用户反馈中学习偏好。实现可以在 prompt 中注入用户信息，或训练个性化的检索/排序模型。个性化能显著提升用户满意度。",
      "context_keywords": ["个性化", "用户画像", "偏好学习", "适应性"]
    },
    {
      "question": "RAG 中的 Chunk Overlap 为什么重要？",
      "ground_truth": "Chunk Overlap 是相邻块之间共享的内容部分，重要性在于：1) 保留边界信息 - 避免重要信息被切断；2) 提高检索鲁棒性 - 即使查询关键词在块边界，仍能被检索到；3) 保持语义连贯 - 避免句子或段落被截断。通常 overlap 设为 chunk size 的 10-20%（如 chunk 500 tokens，overlap 50-100 tokens）。过大的 overlap 会增加存储和检索成本，过小则可能丢失边界信息。需要根据文档特性权衡。",
      "context_keywords": ["重叠", "边界处理", "信息完整性", "检索鲁棒性"]
    },
    {
      "question": "什么是 RAG 中的 Iterative Retrieval？",
      "ground_truth": "Iterative Retrieval 是多轮检索的策略：1) 初次检索获得初步结果；2) 根据结果生成新的查询或判断是否需要更多信息；3) 进行二次检索；4) 重复直到获得足够信息。这类似人类查资料的过程 - 先粗查，发现信息不足后再细查。适合复杂问题，如需要多个知识点的推理任务。实现可以用 Agent 框架（如 LangChain 的 ReAct）或循环调用检索。相比一次检索，迭代检索更灵活但成本更高。",
      "context_keywords": ["迭代检索", "多轮查询", "自适应", "复杂推理"]
    },
    {
      "question": "如何评估 RAG 系统的 Faithfulness？",
      "ground_truth": "Faithfulness 评估答案是否忠实于检索的上下文，方法包括：1) 自动化评估 - 用 LLM 判断答案中的每个陈述是否能在上下文中找到支持；2) NLI 模型 - 使用自然语言推理模型判断答案和上下文的蕴含关系；3) 人工标注 - 人工检查答案和上下文的一致性；4) Claim 提取 - 将答案分解为多个 claim，逐一验证。Ragas 的 Faithfulness 指标通过 LLM 提取答案中的陈述，然后检查每个陈述是否有上下文支持。高 Faithfulness 是 RAG 的核心价值。",
      "context_keywords": ["忠实度", "事实验证", "幻觉检测", "上下文一致性"]
    },
    {
      "question": "RAG 中如何处理代码文档？",
      "ground_truth": "处理代码文档的策略包括：1) 保留代码结构 - 使用语言感知的分块器，避免切断函数或类；2) 添加代码元数据 - 标记语言、函数名、类名；3) 混合检索 - 结合代码语义和标识符匹配；4) 代码理解模型 - 使用 CodeBERT、GraphCodeBERT 等专门的代码 embedding；5) API 文档增强 - 将函数签名、文档字符串单独索引。对于技术文档问答，准确处理代码片段至关重要。",
      "context_keywords": ["代码处理", "语法分析", "代码embedding", "技术文档"]
    },
    {
      "question": "什么是 RAG 的 Cold Start 问题？",
      "ground_truth": "Cold Start 指系统初始没有知识库或知识库很小时的问题。解决方法包括：1) 预加载 - 部署时预先索引基础文档；2) 渐进式构建 - 从用户交互中学习，逐步扩充知识库；3) 外部知识源 - 集成 web 搜索、API 等外部数据源；4) Few-shot 示例 - 在 prompt 中提供通用示例；5) 混合模式 - 知识库不足时降级到纯 LLM 模式。对于新领域应用，需要策略性地收集和索引初始文档集。",
      "context_keywords": ["冷启动", "初始化", "知识库构建", "外部数据"]
    },
    {
      "question": "如何在 RAG 中实现多租户（Multi-tenancy）？",
      "ground_truth": "多租户实现方法包括：1) 命名空间隔离 - 为每个租户分配独立的 collection/namespace；2) 元数据过滤 - 所有文档标记 tenant_id，检索时过滤；3) 独立索引 - 每个租户独立的向量数据库实例；4) 混合模式 - 共享基础知识，私有数据隔离。需要考虑：1) 数据隔离安全性；2) 成本效率；3) 性能影响。对于 SaaS RAG 应用，多租户是必备能力，需要在架构设计初期就考虑。",
      "context_keywords": ["多租户", "数据隔离", "命名空间", "SaaS"]
    },
    {
      "question": "RAG 中的 Hallucination Detection 如何实现？",
      "ground_truth": "幻觉检测方法包括：1) Faithfulness 检查 - 验证答案是否有上下文支持；2) 多模型投票 - 用多个模型生成答案，比较一致性；3) 不确定性估计 - 分析模型的置信度；4) 事实验证 - 与外部知识库交叉验证；5) 人工审核 - 高风险场景的人工复核。可以用 LLM 作为评判者，或训练专门的幻觉检测模型。检测到幻觉后，可以重新检索、降低置信度标记或拒绝回答。",
      "context_keywords": ["幻觉检测", "事实验证", "置信度", "质量控制"]
    },
    {
      "question": "什么是 RAG 中的 Document Ranking？",
      "ground_truth": "Document Ranking 是对检索结果排序的过程，方法包括：1) 向量相似度 - 基于 embedding 距离；2) BM25 分数 - 基于关键词匹配；3) Reranking - 使用 cross-encoder 精细排序；4) 学习排序（LTR）- 训练专门的排序模型；5) 混合排序 - 结合多种信号（相似度、新鲜度、权威性）。排序质量直接影响 RAG 答案质量，因为通常只有 top-k 文档会传给 LLM。优化排序是提升 RAG 性能的关键环节。",
      "context_keywords": ["排序", "reranking", "相关性", "top-k"]
    },
    {
      "question": "如何在 RAG 中处理低资源语言？",
      "ground_truth": "处理低资源语言的策略包括：1) 多语言模型 - 使用 mBERT、XLM-R 等预训练多语言模型；2) 迁移学习 - 从高资源语言迁移；3) 数据增强 - 通过翻译、回译扩充训练数据；4) 跨语言检索 - 将查询翻译为高资源语言检索，结果翻译回来；5) 字符级或子词模型 - 减少词表依赖。对于企业应用，可能需要针对特定领域微调模型，或使用人工翻译建立双语语料。",
      "context_keywords": ["低资源语言", "多语言模型", "迁移学习", "跨语言"]
    },
    {
      "question": "RAG 系统的延迟优化有哪些方法？",
      "ground_truth": "延迟优化方法包括：1) 检索优化 - 使用 HNSW 等快速索引，调整 top-k；2) 模型优化 - 使用量化、蒸馏的小模型；3) 缓存 - 语义缓存常见查询；4) 并行化 - 检索和某些处理步骤并行；5) 流式输出 - 让用户更早看到结果；6) 批处理 - 合并多个请求；7) GPU 加速 - 用 GPU 进行向量计算和推理。需要在各环节测量延迟，找出瓶颈。对于交互式应用，首 token 延迟（TTFT）特别重要。",
      "context_keywords": ["延迟优化", "性能", "并行化", "缓存"]
    },
    {
      "question": "什么是 RAG 中的 Dense Passage Retrieval (DPR)？",
      "ground_truth": "DPR 是使用深度学习训练的密集向量检索方法。与 BM25 等稀疏方法不同，DPR：1) 用 bi-encoder 将查询和文档编码为密集向量；2) 通过对比学习训练，使相关文档在向量空间中接近；3) 检索时用向量相似度（如余弦）排序。DPR 的优势是能捕捉语义相似性，即使查询和文档用词不同。训练需要大量「查询-相关文档」对。DPR 是现代 RAG 系统的主流检索方法，许多嵌入模型（如 bge、e5）都基于这一框架。",
      "context_keywords": ["密集检索", "bi-encoder", "对比学习", "语义检索"]
    },
    {
      "question": "如何在 RAG 中实现领域适配？",
      "ground_truth": "领域适配方法包括：1) 领域微调 - 用领域数据微调 embedding 模型和 LLM；2) 领域词汇 - 构建领域特定的分词器和词典；3) 领域 prompt - 设计包含领域知识的 system prompt；4) 领域评估 - 建立领域特定的评估数据集；5) 专家系统 - 集成领域规则和知识图谱。例如，医疗 RAG 需要理解医学术语，法律 RAG 需要处理法律文本的特殊结构。通用模型在专业领域表现有限，领域适配能显著提升准确度。",
      "context_keywords": ["领域适配", "微调", "专业知识", "垂直领域"]
    },
    {
      "question": "RAG 中的 Retrieval Augmented Fine-tuning 是什么？",
      "ground_truth": "Retrieval Augmented Fine-tuning 是在微调 LLM 时加入检索的方法。训练时：1) 对每个训练样本进行检索，获取相关文档；2) 将文档作为上下文与输入一起训练；3) 让模型学会利用检索上下文。这使得模型在推理时能更好地利用 RAG 提供的上下文。与标准 RAG（冻结 LLM）不同，这种方法调整模型权重，使其「习惯」有外部知识的工作方式。适合需要强领域适配或高质量要求的场景。",
      "context_keywords": ["微调", "检索增强", "模型训练", "领域适配"]
    },
    {
      "question": "什么是 RAG 中的 Query Routing？",
      "ground_truth": "Query Routing 是根据查询类型路由到不同处理流程的技术。例如：1) 事实查询 → RAG 检索；2) 推理问题 → CoT + RAG；3) 闲聊 → 纯 LLM；4) 特定领域 → 对应的知识库。实现方法包括：1) 规则匹配 - 基于关键词或模式；2) 分类模型 - 训练查询分类器；3) LLM 判断 - 用 LLM 分析查询意图。Query Routing 能优化资源使用，避免不必要的检索，提升用户体验。在复杂的多功能系统中尤其重要。",
      "context_keywords": ["查询路由", "意图识别", "多策略", "智能分发"]
    },
    {
      "question": "如何评估 RAG 系统的 Answer Relevancy？",
      "ground_truth": "Answer Relevancy 评估答案是否真正回答了问题，方法包括：1) LLM 评估 - 让 LLM 判断答案是否切题；2) 逆向验证 - 从答案生成问题，看是否与原问题相似；3) 语义相似度 - 计算问题和答案的向量相似度；4) 人工评估 - 标注样本进行评估。Ragas 的 Answer Relevancy 通过让 LLM 从答案生成多个问题，然后计算这些问题与原问题的相似度。低相关性可能表示答案跑题、过于笼统或包含过多无关信息。",
      "context_keywords": ["答案相关性", "切题程度", "逆向验证", "质量评估"]
    },
    {
      "question": "RAG 中如何处理矛盾信息？",
      "ground_truth": "处理矛盾信息的策略包括：1) 冲突检测 - 用 NLI 模型或 LLM 检测检索结果中的矛盾；2) 来源评估 - 根据文档权威性、新鲜度判断可信度；3) 多数投票 - 当多个文档矛盾时，采纳多数观点；4) 展示多方观点 - 不做判断，呈现不同说法；5) 人工介入 - 对高风险矛盾进行人工审核。在 prompt 中可以指示模型：「如果发现矛盾信息，请说明不同来源的观点」。处理矛盾是 RAG 鲁棒性的重要方面。",
      "context_keywords": ["冲突检测", "矛盾处理", "来源可信度", "多视角"]
    },
    {
      "question": "什么是 RAG 中的 Active Learning？",
      "ground_truth": "Active Learning 是让系统主动识别需要改进的地方并请求标注的方法。在 RAG 中：1) 识别低置信度查询 - 检索分数低、多模型结果不一致；2) 请求人工反馈 - 标注正确答案或相关文档；3) 迭代改进 - 用新标注数据微调模型或更新知识库；4) 优先级排序 - 聚焦最有价值的样本。这能用较少标注成本持续提升系统。适合实际部署后的持续优化，特别是处理 long-tail 问题。",
      "context_keywords": ["主动学习", "人工反馈", "持续改进", "标注优化"]
    },
    {
      "question": "RAG 系统如何处理数学公式和科学符号？",
      "ground_truth": "处理数学内容的策略包括：1) LaTeX 保留 - 在分块时保持 LaTeX 公式完整；2) 公式解析 - 使用工具（如 MathJax）将公式转为文本描述；3) 多模态处理 - 将公式渲染为图片，用视觉模型处理；4) 专门模型 - 使用 Minerva、Galactica 等科学领域模型；5) 符号计算 - 集成 SymPy、Wolfram Alpha 等工具。对于学术、技术文档，准确处理公式至关重要。",
      "context_keywords": ["数学公式", "LaTeX", "科学文档", "符号处理"]
    },
    {
      "question": "如何在 RAG 中实现解释性（Explainability）？",
      "ground_truth": "实现解释性的方法包括：1) 显示检索来源 - 列出答案依据的文档；2) 相关性分数 - 展示每个来源的置信度；3) 高亮引用 - 标记答案中具体来自哪段文本；4) 推理步骤 - 使用 CoT 展示思考过程；5) 可视化 - 图表展示检索和生成流程；6) 反事实解释 - 说明如果没有某个文档，答案会如何变化。良好的解释性提升用户信任，对于监管严格的领域（医疗、金融）尤为重要。",
      "context_keywords": ["可解释性", "透明度", "来源追溯", "用户信任"]
    },
    {
      "question": "RAG 中的 Ensemble Methods 如何应用？",
      "ground_truth": "集成方法在 RAG 中的应用包括：1) 多检索器集成 - 使用多个 embedding 模型，融合结果；2) 多生成器投票 - 用多个 LLM 生成答案，选择最佳或综合；3) 多策略融合 - 结合不同的 RAG 流程（如标准 RAG + HyDE）；4) 分数融合 - 用 RRF 或加权平均合并多个排序；5) 分层集成 - 快速方法初筛，精确方法精排。集成通常能提高准确度和鲁棒性，但增加计算成本。适合高要求场景。",
      "context_keywords": ["集成方法", "多模型", "融合策略", "鲁棒性"]
    },
    {
      "question": "什么是 RAG 中的 Document Expansion？",
      "ground_truth": "Document Expansion 是在索引前扩展文档内容的技术。方法包括：1) 生成问题 - 用 LLM 为每个文档生成可能的问题，与文档一起索引；2) 摘要增强 - 添加文档摘要作为额外上下文；3) 关键词提取 - 提取并添加关键术语；4) 同义词扩展 - 添加重要词汇的同义词。这能提高检索召回率，因为用户查询可能匹配生成的问题而非原文。特别适合文档用词和用户查询习惯差异大的场景。",
      "context_keywords": ["文档扩展", "问题生成", "索引增强", "召回优化"]
    },
    {
      "question": "RAG 系统如何处理PDF文档的特殊格式？",
      "ground_truth": "处理 PDF 的策略包括：1) 文本提取 - 使用 PyPDF2、pdfplumber 等工具；2) 布局分析 - 识别标题、段落、表格、图片的位置关系；3) 保留结构 - 维护文档的层次结构（章节、小节）；4) OCR - 对扫描版 PDF 使用光学字符识别；5) 元数据提取 - 获取页码、作者、创建日期；6) 图表处理 - 提取并单独处理图片和表格。高质量的 PDF 解析对 RAG 准确度影响很大，特别是学术论文、技术文档。",
      "context_keywords": ["PDF处理", "文本提取", "布局分析", "OCR"]
    },
    {
      "question": "如何在 RAG 中实现 Feedback Loop？",
      "ground_truth": "反馈循环实现方法包括：1) 显式反馈 - 收集用户点赞/点踩、评分；2) 隐式反馈 - 跟踪用户行为（停留时间、后续查询）；3) 人工审核 - 定期审查系统输出；4) A/B 测试 - 对比不同策略效果；5) 持续学习 - 用反馈数据微调模型或更新知识库；6) 监控指标 - 跟踪关键性能指标变化。反馈循环是 RAG 系统从部署到优秀的关键，需要建立完整的数据收集、分析和迭代机制。",
      "context_keywords": ["反馈循环", "用户反馈", "持续优化", "A/B测试"]
    },
    {
      "question": "RAG 中的 Context Window 管理策略有哪些？",
      "ground_truth": "上下文窗口管理策略包括：1) 优先级排序 - 最相关的文档放前面；2) 截断策略 - 超长文档截取最相关部分；3) 摘要压缩 - 对次要文档使用摘要；4) 分层提供 - 先给关键信息，必要时再扩展；5) 动态调整 - 根据查询复杂度调整上下文量；6) Token 预算 - 为系统 prompt、上下文、生成预留合适比例。需要平衡信息完整性和成本/性能。对于长上下文模型（如 Claude 100k），策略会有所不同。",
      "context_keywords": ["上下文管理", "token预算", "窗口限制", "优先级"]
    },
    {
      "question": "什么是 RAG 中的 Self-RAG？",
      "ground_truth": "Self-RAG 是让模型自主判断何时需要检索的方法。流程是：1) 接收查询；2) 模型判断是否需要外部知识；3) 如需要则触发检索；4) 生成答案后，自我评估质量；5) 如不满意则重新检索或改写。这通过训练模型输出特殊 token（如 [Retrieve]、[IsRel]、[IsSup]）实现。Self-RAG 的优势是更灵活，只在必要时检索，且能自我纠错。这是 RAG 走向 Agent 化的重要方向，需要特殊训练数据和模型架构支持。",
      "context_keywords": ["自主检索", "自我评估", "灵活RAG", "智能决策"]
    },
    {
      "question": "如何评估和优化 RAG 系统的成本效益？",
      "ground_truth": "成本效益评估包括：1) Token 成本 - 跟踪 embedding 和 LLM 调用的 token 数；2) 基础设施成本 - 向量数据库、服务器、GPU；3) 时间成本 - 开发和维护时间；4) 质量收益 - 准确率提升带来的价值；5) 用户体验 - 延迟和满意度。优化策略：1) 模型选择 - 任务匹配合适大小的模型；2) 缓存 - 减少重复调用；3) 批处理 - 提高吞吐；4) 检索优化 - 减少不必要的检索。需要建立 ROI 模型，平衡成本和效果。",
      "context_keywords": ["成本分析", "ROI", "效率优化", "资源管理"]
    },
    {
      "question": "RAG 系统在生产环境中的监控指标有哪些？",
      "ground_truth": "关键监控指标包括：1) 性能指标 - QPS、延迟（p50/p95/p99）、吞吐量；2) 质量指标 - 检索准确率、用户满意度、答案采纳率；3) 成本指标 - Token 消耗、API 调用次数、基础设施成本；4) 可用性 - 服务可用性、错误率；5) 资源使用 - CPU、内存、GPU、存储；6) 业务指标 - 用户留存、任务完成率。需要设置告警阈值，建立 dashboard 实时监控。对异常需要有自动告警和应急响应流程。",
      "context_keywords": ["系统监控", "性能指标", "质量跟踪", "告警机制"]
    },
    {
      "question": "RAG 技术的未来发展趋势是什么？",
      "ground_truth": "主要趋势包括：1) 多模态 RAG - 整合文本、图像、音频、视频；2) Agent 化 - 更智能的自主检索和推理；3) 实时性 - 更好地处理动态更新的知识；4) 个性化 - 适应用户偏好和上下文；5) 效率提升 - 更小的模型、更快的检索；6) 端到端优化 - 联合训练检索和生成；7) 知识编辑 - 更灵活地更新和修正知识；8) 隐私保护 - 本地化部署、联邦学习。RAG 从工具向智能系统演进，将成为 AI 应用的标准组件。",
      "context_keywords": ["技术趋势", "未来方向", "多模态", "智能化"]
    },
    {
      "question": "如何构建一个企业级的 RAG 系统？",
      "ground_truth": "构建企业级 RAG 需要考虑：1) 架构设计 - 微服务化、可扩展、高可用；2) 数据管理 - 文档版本控制、增量更新、备份恢复；3) 安全合规 - 访问控制、数据加密、审计日志、GDPR 合规；4) 性能优化 - 负载均衡、缓存、CDN；5) 监控运维 - 完整的监控、告警、日志系统；6) 质量保证 - 评估框架、A/B 测试、持续改进；7) 成本控制 - 资源优化、成本监控；8) 用户体验 - 良好的 UI、反馈机制。需要跨团队协作（AI、工程、产品、安全）。",
      "context_keywords": ["企业应用", "系统架构", "安全合规", "生产部署"]
    }
  ]
}
